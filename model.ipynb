{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b32c024e-6f28-4739-9c55-ff063b9992ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   product_id     product_name  ... customer_location  target_column\n0        2001           Tablet  ...          Illinois              1\n1        2002        Microwave  ...           Georgia              0\n2        2003             Desk  ...        Washington              1\n3        2004          Monitor  ...           Florida              1\n4        2005  Air Conditioner  ...           Arizona              1\n5        2006        Bookshelf  ...            Oregon              0\n6        2007          Toaster  ...              Ohio              1\n7        2008          Printer  ...          Michigan              0\n8        2009   Vacuum Cleaner  ...             Texas              1\n9        2010       Smartwatch  ...        California              1\n\n[10 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "from azure.storage.blob import BlobServiceClient\n",
    "import io\n",
    "import pandas as pd\n",
    "\n",
    "connection_string = \"DefaultEndpointsProtocol=https;AccountName=thirdtry3;AccountKey=R2tz5fvj0ZdyJ2Cjb4OjyRlaNc1MS9tTPfc5uWjWjnpzm2C7MWtZr1k+7Hnawhesoj/eIPfO05+F+AStoGzFjQ==;EndpointSuffix=core.windows.net\"\n",
    "\n",
    "container_name = \"mycontainer\"\n",
    "blob_name = \"product_dataset.csv\"\n",
    "\n",
    "blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
    "\n",
    "blob_client = blob_service_client.get_blob_client(container=container_name, blob=blob_name)\n",
    "\n",
    "blob_data = blob_client.download_blob()\n",
    "\n",
    "csv_data = blob_data.readall()\n",
    "\n",
    "data_frame = pd.read_csv(io.BytesIO(csv_data))\n",
    "\n",
    "print(data_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a2567f5-597f-4020-aa28-247d8648260f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   product_id  price  ...  log_quantity_sold  price_per_unit\n0        2001    500  ...           2.944439       26.315789\n1        2002    200  ...           2.708050       13.333333\n2        2003    250  ...           2.397895       22.727273\n3        2004    180  ...           3.258097        6.923077\n4        2005   1200  ...           2.079442      150.000000\n5        2006    150  ...           2.833213        8.823529\n6        2007     40  ...           3.931826        0.784314\n7        2008    250  ...           2.564949       19.230769\n8        2009    300  ...           3.044522       14.285714\n9        2010    220  ...           3.433987        7.096774\n\n[10 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data_frame['cumulative_quantity_sold'] = data_frame['quantity_sold'].cumsum()\n",
    "\n",
    "data_frame['rolling_avg_price'] = data_frame['price'].rolling(window=3).mean()\n",
    "data_frame['rolling_avg_quantity_sold'] = data_frame['quantity_sold'].rolling(window=3).mean()\n",
    "data_frame['rolling_avg_discount'] = data_frame['discount'].rolling(window=3).mean()\n",
    "\n",
    "if 'date' in data_frame.columns:\n",
    "    data_frame['year'] = data_frame['date'].dt.year\n",
    "    data_frame['month'] = data_frame['date'].dt.month\n",
    "    data_frame['day'] = data_frame['date'].dt.day\n",
    "    data_frame['weekday'] = data_frame['date'].dt.weekday\n",
    "\n",
    "data_frame = pd.get_dummies(data_frame, columns=['category', 'customer_location'], drop_first=True)\n",
    "\n",
    "data_frame['price_quantity_interaction'] = data_frame['price'] * data_frame['quantity_sold']\n",
    "\n",
    "if data_frame['price'].skew() > 1:\n",
    "    data_frame['log_price'] = np.log1p(data_frame['price'])\n",
    "\n",
    "if data_frame['quantity_sold'].skew() > 1:\n",
    "    data_frame['log_quantity_sold'] = np.log1p(data_frame['quantity_sold'])\n",
    "\n",
    "data_frame['price_per_unit'] = data_frame['price'] / (data_frame['quantity_sold'] + 1)\n",
    "\n",
    "data_frame = data_frame.drop(columns=['product_name', 'target_column'])\n",
    "\n",
    "print(data_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb9e6a65-e7cb-4139-a8d9-872cefafcaec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   product_id     product_name  ... customer_location  target_column\n0        2001           Tablet  ...          Illinois              1\n1        2002        Microwave  ...           Georgia              0\n2        2003             Desk  ...        Washington              1\n3        2004          Monitor  ...           Florida              1\n4        2005  Air Conditioner  ...           Arizona              1\n5        2006        Bookshelf  ...            Oregon              0\n6        2007          Toaster  ...              Ohio              1\n7        2008          Printer  ...          Michigan              0\n8        2009   Vacuum Cleaner  ...             Texas              1\n9        2010       Smartwatch  ...        California              1\n\n[10 rows x 9 columns]\nThe 'target_column' does not exist in the DataFrame.\n"
     ]
    }
   ],
   "source": [
    "%python\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "import io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "connection_string = \"DefaultEndpointsProtocol=https;AccountName=thirdtry3;AccountKey=R2tz5fvj0ZdyJ2Cjb4OjyRlaNc1MS9tTPfc5uWjWjnpzm2C7MWtZr1k+7Hnawhesoj/eIPfO05+F+AStoGzFjQ==;EndpointSuffix=core.windows.net\"\n",
    "\n",
    "container_name = \"mycontainer\"\n",
    "blob_name = \"product_dataset.csv\"\n",
    "\n",
    "blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
    "\n",
    "blob_client = blob_service_client.get_blob_client(container=container_name, blob=blob_name)\n",
    "\n",
    "blob_data = blob_client.download_blob()\n",
    "\n",
    "csv_data = blob_data.readall()\n",
    "\n",
    "data_frame = pd.read_csv(io.BytesIO(csv_data))\n",
    "\n",
    "print(data_frame)\n",
    "\n",
    "data_frame['cumulative_quantity_sold'] = data_frame['quantity_sold'].cumsum()\n",
    "\n",
    "data_frame['rolling_avg_price'] = data_frame['price'].rolling(window=3).mean()\n",
    "data_frame['rolling_avg_quantity_sold'] = data_frame['quantity_sold'].rolling(window=3).mean()\n",
    "data_frame['rolling_avg_discount'] = data_frame['discount'].rolling(window=3).mean()\n",
    "\n",
    "data_frame = pd.get_dummies(data_frame, columns=['category', 'customer_location'], drop_first=True)\n",
    "\n",
    "data_frame['price_quantity_interaction'] = data_frame['price'] * data_frame['quantity_sold']\n",
    "\n",
    "if data_frame['price'].skew() > 1:\n",
    "    data_frame['log_price'] = np.log1p(data_frame['price'])\n",
    "\n",
    "if data_frame['quantity_sold'].skew() > 1:\n",
    "    data_frame['log_quantity_sold'] = np.log1p(data_frame['quantity_sold'])\n",
    "\n",
    "data_frame['price_per_unit'] = data_frame['price'] / (data_frame['quantity_sold'] + 1)\n",
    "\n",
    "columns_to_drop = ['product_name', 'target_column']\n",
    "data_frame = data_frame.drop(columns=[col for col in columns_to_drop if col in data_frame.columns])\n",
    "\n",
    "if 'target_column' in data_frame.columns:\n",
    "    X = data_frame.drop(columns=['target_column'])\n",
    "    y = data_frame['target_column']\n",
    "\n",
    "    X = X.dropna()\n",
    "    y = y[X.index]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    print(X_train)\n",
    "else:\n",
    "    print(\"The 'target_column' does not exist in the DataFrame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "915d143a-88db-4fd6-bdeb-c2c3b4c02a68",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 1.1368683772161603e-13\nMean Squared Error (MSE): 1.2924697071141057e-26\nRoot Mean Squared Error (RMSE): 1.1368683772161603e-13\nR-squared (RÂ²): nan\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.11/site-packages/sklearn/metrics/_regression.py:996: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n  warnings.warn(msg, UndefinedMetricWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "data = {\n",
    "    'Feature1': [1, 2, np.nan, 4, 5],\n",
    "    'Feature2': [5, 6, 7, 8, 9],\n",
    "    'Price': [100, 200, 300, 400, 500]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "X = df.drop(columns=['Price'])\n",
    "y = df['Price']\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"R-squared (RÂ²): {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "40f42100-2698-4f99-9b5b-6c62a83c5584",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 1.1368683772161603e-13\nMean Squared Error (MSE): 1.2924697071141057e-26\nRoot Mean Squared Error (RMSE): 1.1368683772161603e-13\nR-squared (RÂ²): nan\nCross-Validation RMSE Scores: [0.00000000e+00 1.70530257e-13 0.00000000e+00 1.13686838e-13\n 0.00000000e+00]\nMean CV RMSE: 5.684341886080802e-14\nCross-Validation RÂ² Scores: [nan nan nan nan nan]\nMean CV RÂ²: nan\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.11/site-packages/sklearn/metrics/_regression.py:996: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n  warnings.warn(msg, UndefinedMetricWarning)\n/databricks/python/lib/python3.11/site-packages/sklearn/metrics/_regression.py:996: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n  warnings.warn(msg, UndefinedMetricWarning)\n/databricks/python/lib/python3.11/site-packages/sklearn/metrics/_regression.py:996: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n  warnings.warn(msg, UndefinedMetricWarning)\n/databricks/python/lib/python3.11/site-packages/sklearn/metrics/_regression.py:996: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n  warnings.warn(msg, UndefinedMetricWarning)\n/databricks/python/lib/python3.11/site-packages/sklearn/metrics/_regression.py:996: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n  warnings.warn(msg, UndefinedMetricWarning)\n/databricks/python/lib/python3.11/site-packages/sklearn/metrics/_regression.py:996: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n  warnings.warn(msg, UndefinedMetricWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"R-squared (RÂ²): {r2}\")\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "cv_rmse_scores = cross_val_score(model, X_imputed, y, cv=kf, scoring='neg_root_mean_squared_error')\n",
    "cv_r2_scores = cross_val_score(model, X_imputed, y, cv=kf, scoring='r2')\n",
    "\n",
    "cv_rmse_scores = -cv_rmse_scores\n",
    "\n",
    "print(f\"Cross-Validation RMSE Scores: {cv_rmse_scores}\")\n",
    "print(f\"Mean CV RMSE: {cv_rmse_scores.mean()}\")\n",
    "\n",
    "print(f\"Cross-Validation RÂ² Scores: {cv_r2_scores}\")\n",
    "print(f\"Mean CV RÂ²: {cv_r2_scores.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "617f0c3d-5abc-4d63-8789-6f110b4213ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.06946967833526876\nModel successfully uploaded to Azure Blob Storage as linear_regression_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X = np.random.rand(100, 5)\n",
    "y = np.random.rand(100)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "\n",
    "model_filename = \"linear_regression_model.pkl\"\n",
    "joblib.dump(model, model_filename)\n",
    "\n",
    "connection_string = \"DefaultEndpointsProtocol=https;AccountName=thirdtry3;AccountKey=R2tz5fvj0ZdyJ2Cjb4OjyRlaNc1MS9tTPfc5uWjWjnpzm2C7MWtZr1k+7Hnawhesoj/eIPfO05+F+AStoGzFjQ==;EndpointSuffix=core.windows.net\"\n",
    "container_name = \"mycontainer\"\n",
    "model_blob_name = \"linear_regression_model.pkl\"\n",
    "\n",
    "blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
    "\n",
    "blob_client = blob_service_client.get_blob_client(container=container_name, blob=model_blob_name)\n",
    "\n",
    "try:\n",
    "    with open(model_filename, \"rb\") as data:\n",
    "        blob_client.upload_blob(data, overwrite=True)  # overwrite=True to replace any existing file\n",
    "\n",
    "    print(f\"Model successfully uploaded to Azure Blob Storage as {model_blob_name}\")\n",
    "\n",
    "    os.remove(model_filename)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error uploading model to Azure Blob Storage: {e}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "model.py",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}